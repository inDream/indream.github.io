<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>barcode scanner wasm</title>
<style>
html, body { height: 100%; }
</style>
</head>

<body>
<div>
<input id="upFile" type="file" style="display: block" accept="image/*" capture>
<video id="live" width="720" height="1280" autoplay style="border:5px solid #000000; display:none;"> </video>
<canvas id="canvas" style="border:5px solid #000000"> </canvas>
</div>
</body>

<script src="./a.out.js"></script>

<script>

// Execute the application code when the WebAssembly module is ready.
Module.onRuntimeInitialized = async _ => {

	// wrap all C functions using cwrap. Note that we have to provide crwap with the function signature.
	const api = {
		scan_image: Module.cwrap('scan_image', '', ['number', 'number', 'number']),
		create_buffer: Module.cwrap('create_buffer', 'number', ['number', 'number']),
		destroy_buffer: Module.cwrap('destroy_buffer', '', ['number']),
	};

	const video = document.getElementById("live");
	const canvas = document.getElementById("canvas");
	const ctx = canvas.getContext('2d');
	const desiredHeight = document.body.clientHeight - 50; //1280;
	const desiredWidth = Math.round(desiredHeight * 9 / 16); //720;
	canvas.height = desiredHeight;
	canvas.width = desiredWidth;
	let ratio = 1;
	
	const upFile = document.getElementById('upFile');
	upFile.addEventListener('change', (e) => {
		console.log(upFile.files);
		let files = e.target.files;
		var reader = new FileReader();
		reader.readAsArrayBuffer(files[0]);
		reader.onload = async function() {
			console.log(reader.result);
			let blob = new Blob([new Uint8Array(reader.result)], {type: files[0].type });
			let b = await createImageBitmap(blob);
			const canvas2 = document.createElement('canvas');
			const context = canvas2.getContext('2d');
			canvas2.width = b.width;
			canvas2.height = b.height;
			context.drawImage(b, 0, 0);
			let image = context.getImageData(0, 0, b.width, b.height);
			
			ratio = b.width / desiredWidth;
			var oc = document.createElement('canvas'),
				octx = oc.getContext('2d');
			oc.width = b.width * 0.5;
			oc.height = b.height * 0.5;
			octx.drawImage(b, 0, 0, oc.width, oc.height);
			// step 2
			octx.drawImage(oc, 0, 0, oc.width * 0.5, oc.height * 0.5);
			// step 3, resize to final size
			ctx.drawImage(oc, 0, 0, oc.width * 0.5, oc.height * 0.5,
			0, 0, canvas.width, canvas.height);

			// convert the image data to grayscale 
			const grayData = []
			const d = image.data;
			for (var i = 0, j = 0; i < d.length; i += 4, j++) {
				grayData[j] = (d[i] * 66 + d[i + 1] * 129 + d[i + 2] * 25 + 4096) >> 8;
			}

			// put the data into the allocated buffer
			const p = api.create_buffer(image.width, image.height);
			Module.HEAP8.set(grayData, p);

			// call the scanner function
			api.scan_image(p, image.width, image.height)

			// clean up (this is not really necessary in this example, but is used to demonstrate how you can manage Wasm heap memory from the js environment)
			api.destroy_buffer(p);
		};
	});

	// settings for the getUserMedia call
	const constraints = {
		audio: false,
		video: {
			facingMode: "environment",
			// the browser will try to honor this resolution, but it may end up being lower.
			width: desiredWidth,
			height: desiredHeight
		}
	};

	// open the webcam stream
	navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
		// stream is a MediaStream object
		video.srcObject = stream;
		video.play();

		// tell the canvas which resolution we ended up getting from the webcam
		const track = stream.getVideoTracks()[0];
		const actualSettings = track.getSettings();
		console.log(actualSettings.width, actualSettings.height)
		canvas.width = actualSettings.width;
		canvas.height = actualSettings.height;

		// every k milliseconds, we draw the contents of the video to the canvas and run the detector.
		const timer = setInterval(detectSymbols, 250);

	}).catch((e) => {
		throw e
	});

	function detectSymbols() {
		// grab a frame from the media source and draw it to the canvas
		ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

		// get the image data from the canvas
		const image = ctx.getImageData(0, 0, canvas.width, canvas.height)

		// convert the image data to grayscale 
		const grayData = []
		const d = image.data;
		for (var i = 0, j = 0; i < d.length; i += 4, j++) {
			grayData[j] = (d[i] * 66 + d[i + 1] * 129 + d[i + 2] * 25 + 4096) >> 8;
		}

		// put the data into the allocated buffer
		const p = api.create_buffer(image.width, image.height);
		Module.HEAP8.set(grayData, p);

		// call the scanner function
		api.scan_image(p, image.width, image.height)

		// clean up (this is not really necessary in this example, but is used to demonstrate how you can manage Wasm heap memory from the js environment)
		api.destroy_buffer(p);

	}

	function drawPoly(ctx, poly) {
		// drawPoly expects a flat array of coordinates forming a polygon (e.g. [x1,y1,x2,y2,... etc])
		ctx.beginPath();
		ctx.moveTo(poly[0]/ratio, poly[1]/ratio);
		for (item = 2; item < poly.length - 1; item += 2) {
			ctx.lineTo(poly[item]/ratio, poly[item + 1]/ratio);
		}
		ctx.lineWidth = 2;
		ctx.strokeStyle = "#FF0000";
		ctx.closePath();
		ctx.stroke();
	
		/*ctx.beginPath();
		ctx.moveTo(poly[0]/ratio, poly[1]/ratio);
		for (item = 2; item < poly.length - 1; item += 2) {
			ctx.lineTo(poly[item]/ratio, poly[item + 1]/ratio);
			ctx.lineWidth = 5;
			ctx.strokeStyle = "#FF0000";
			ctx.closePath();
			ctx.stroke();
			ctx.moveTo(poly[item]/ratio, poly[item + 1]/ratio); // extra
			ctx.beginPath();
		}
		ctx.closePath();
		ctx.stroke();*/
	}

	function renderData(ctx, data, x, y) {
		ctx.font = "15px Arial";
		ctx.fillStyle = "red";
		ctx.fillText(data, x, y);
	}

	// set the function that should be called whenever a barcode is detected
	Module['processResult'] = (symbol, data, polygon) => {
		console.log("Data liberated from WASM heap:")
		console.log(symbol)
		console.log(data)
		console.log(polygon)

		// draw the bounding polygon
		drawPoly(ctx, polygon)

		// render the data at the polygon's left edge
		renderData(ctx, data, polygon[0], polygon[1] - 10)
	}

}
</script>
</html>
